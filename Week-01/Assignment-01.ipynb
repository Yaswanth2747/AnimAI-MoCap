{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c151e203",
   "metadata": {},
   "source": [
    "# Assignment 01: Exploratory Data Analysis & Data Preprocessing\n",
    "### Seasons of Code - AnimAI\n",
    "---\n",
    "## Introduction\n",
    "\n",
    "Welcome to your first assignment for the AnimAI project! In this assignment, you'll work with a dataset containing popularity statistics for various cartoon characters across different countries. This dataset has intentionally been made \"messy\" with outliers, missing values, and inconsistencies to simulate real-world data challenges.\n",
    "\n",
    "The skills you learn in this assignment will form the foundation for more advanced machine learning and AI applications in later weeks of the project.\n",
    "\n",
    ">**Objective**: To perform exploratory data analysis and preprocessing on a cartoon character popularity dataset, applying fundamental concepts of data cleaning, visualization, and statistical analysis.\n",
    "\n",
    "\n",
    "## Dataset Overview\n",
    "\n",
    "The dataset `cartoon_popularity_data.csv` contains information about cartoon character popularity across various countries with the following columns:\n",
    "\n",
    "- `Character`: Name of the cartoon character\n",
    "- `Country`: Country where the popularity was measured\n",
    "- `Popularity_Score`: A rating from 0-100 indicating popularity (though some entries may fall outside this range)\n",
    "- `Avg_Episodes_Watched_Per_Year`: Average number of episodes watched per viewer per year\n",
    "- `Merchandise_Revenue_MillionUSD`: Revenue generated from character merchandise in millions of USD\n",
    "\n",
    "First, let's import the necessary libraries and load our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d3f250e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (10000, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Character</th>\n",
       "      <th>Country</th>\n",
       "      <th>Popularity_Score</th>\n",
       "      <th>Avg_Episodes_Watched_Per_Year</th>\n",
       "      <th>Merchandise_Revenue_MillionUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shinchan</td>\n",
       "      <td>Canada</td>\n",
       "      <td>74.06677446676758</td>\n",
       "      <td>80</td>\n",
       "      <td>3.949924724368964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paw Patrol</td>\n",
       "      <td>France</td>\n",
       "      <td>80.58192518328079</td>\n",
       "      <td>48</td>\n",
       "      <td>22.31606244865129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SpongeBob SquarePants</td>\n",
       "      <td>Russia</td>\n",
       "      <td>37.853437720835345</td>\n",
       "      <td>127.5</td>\n",
       "      <td>258.92694939230086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Motu Patlu</td>\n",
       "      <td>UK</td>\n",
       "      <td>83.41104266407503</td>\n",
       "      <td>50</td>\n",
       "      <td>27.430804382862224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mr Bean</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>76.83135775923722</td>\n",
       "      <td>9</td>\n",
       "      <td>40.715313915210565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mr Bean</td>\n",
       "      <td>Russia</td>\n",
       "      <td>74.49889820916066</td>\n",
       "      <td>100</td>\n",
       "      <td>89.88446547664522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shinchan</td>\n",
       "      <td>China</td>\n",
       "      <td>42.215996679968406</td>\n",
       "      <td>53</td>\n",
       "      <td>47.33693889068305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Shinchan</td>\n",
       "      <td>France</td>\n",
       "      <td>29.350012864742613</td>\n",
       "      <td>5</td>\n",
       "      <td>87.70944109744121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Motu Patlu</td>\n",
       "      <td>Australia</td>\n",
       "      <td>53.937903011962575</td>\n",
       "      <td>72</td>\n",
       "      <td>60.295513861562675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Motu Patlu</td>\n",
       "      <td>Saudi Arabia</td>\n",
       "      <td>48.59904633166138</td>\n",
       "      <td>73</td>\n",
       "      <td>13.710754985476516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mickey Mouse</td>\n",
       "      <td>Australia</td>\n",
       "      <td>67.16869596382831</td>\n",
       "      <td>71</td>\n",
       "      <td>76.62796725880435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Doraemon</td>\n",
       "      <td>Canada</td>\n",
       "      <td>33.04284890804987</td>\n",
       "      <td>60.0</td>\n",
       "      <td>22.20944392967342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Pokemon</td>\n",
       "      <td>UK</td>\n",
       "      <td>41.1102276049738</td>\n",
       "      <td>11</td>\n",
       "      <td>295.29706777569197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mr Bean</td>\n",
       "      <td>China</td>\n",
       "      <td>24.98064478821005</td>\n",
       "      <td>61</td>\n",
       "      <td>85.7407223543689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Shinchan</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>86.46503940302155</td>\n",
       "      <td>26</td>\n",
       "      <td>98.54557553419286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Paw Patrol</td>\n",
       "      <td>Australia</td>\n",
       "      <td>57.91802908162562</td>\n",
       "      <td>100</td>\n",
       "      <td>5.9640913891314025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Paw Patrol</td>\n",
       "      <td>UAE</td>\n",
       "      <td>40.37755513182775</td>\n",
       "      <td>77</td>\n",
       "      <td>59.85739619981068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Motu Patlu</td>\n",
       "      <td>Canada</td>\n",
       "      <td>64.55007888376495</td>\n",
       "      <td>14</td>\n",
       "      <td>62.49476629381619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Tom and Jerry</td>\n",
       "      <td>Canada</td>\n",
       "      <td>83.37449546398071</td>\n",
       "      <td>124.5</td>\n",
       "      <td>80.90289438324909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Shinchan</td>\n",
       "      <td>UK</td>\n",
       "      <td>15.544790977499046</td>\n",
       "      <td>31</td>\n",
       "      <td>21.15613392041784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Character       Country    Popularity_Score  \\\n",
       "0                Shinchan        Canada   74.06677446676758   \n",
       "1              Paw Patrol        France   80.58192518328079   \n",
       "2   SpongeBob SquarePants        Russia  37.853437720835345   \n",
       "3              Motu Patlu            UK   83.41104266407503   \n",
       "4                 Mr Bean         Egypt   76.83135775923722   \n",
       "5                 Mr Bean        Russia   74.49889820916066   \n",
       "6                Shinchan         China  42.215996679968406   \n",
       "7                Shinchan        France  29.350012864742613   \n",
       "8              Motu Patlu     Australia  53.937903011962575   \n",
       "9              Motu Patlu  Saudi Arabia   48.59904633166138   \n",
       "10           Mickey Mouse     Australia   67.16869596382831   \n",
       "11               Doraemon        Canada   33.04284890804987   \n",
       "12                Pokemon            UK    41.1102276049738   \n",
       "13                Mr Bean         China   24.98064478821005   \n",
       "14               Shinchan        Brazil   86.46503940302155   \n",
       "15             Paw Patrol     Australia   57.91802908162562   \n",
       "16             Paw Patrol           UAE   40.37755513182775   \n",
       "17             Motu Patlu        Canada   64.55007888376495   \n",
       "18          Tom and Jerry        Canada   83.37449546398071   \n",
       "19               Shinchan            UK  15.544790977499046   \n",
       "\n",
       "   Avg_Episodes_Watched_Per_Year Merchandise_Revenue_MillionUSD  \n",
       "0                             80              3.949924724368964  \n",
       "1                             48              22.31606244865129  \n",
       "2                          127.5             258.92694939230086  \n",
       "3                             50             27.430804382862224  \n",
       "4                              9             40.715313915210565  \n",
       "5                            100              89.88446547664522  \n",
       "6                             53              47.33693889068305  \n",
       "7                              5              87.70944109744121  \n",
       "8                             72             60.295513861562675  \n",
       "9                             73             13.710754985476516  \n",
       "10                            71              76.62796725880435  \n",
       "11                          60.0              22.20944392967342  \n",
       "12                            11             295.29706777569197  \n",
       "13                            61               85.7407223543689  \n",
       "14                            26              98.54557553419286  \n",
       "15                           100             5.9640913891314025  \n",
       "16                            77              59.85739619981068  \n",
       "17                            14              62.49476629381619  \n",
       "18                         124.5              80.90289438324909  \n",
       "19                            31              21.15613392041784  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set figure size for better readability\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['axes.grid'] = True\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'cartoon_popularity_data.csv' # Fill here with the path to your dataset\n",
    "\n",
    "# Check if the file exists\n",
    "try:\n",
    "    with open(file_path, 'r') as f:\n",
    "        pass\n",
    "except FileNotFoundError:\n",
    "    print(f\"File {file_path} not found. Please check the path and try again.\")\n",
    "    exit()\n",
    "\n",
    "# Read the dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50fe734",
   "metadata": {},
   "source": [
    "## Part 1: Exploratory Data Analysis (EDA)\n",
    "\n",
    "### Task 1.1: Basic Data Exploration\n",
    "\n",
    "- Display the shape of the dataset\n",
    "- Check the data types of each column\n",
    "- Generate basic statistics using `describe()`\n",
    "- Check for missing values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c41e1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac326f6",
   "metadata": {},
   "source": [
    "### Task 1.2: Data Visualization\n",
    "\n",
    "Create appropriate visualizations to explore the dataset:\n",
    "\n",
    "1. Distribution of popularity scores (histogram)\n",
    "2. Average episodes watched by character (bar chart)\n",
    "3. Merchandise revenue by country (box plot)\n",
    "4. Correlation heatmap between numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8d7516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721f4011",
   "metadata": {},
   "source": [
    "### Task 1.3: Identifying Data Issues\n",
    "\n",
    "Based on your exploration:\n",
    "- List all data quality issues you've found\n",
    "- Categorize them (missing values, outliers, inconsistent formats, etc.)\n",
    "- Explain how each issue might affect your analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b460ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b763fb",
   "metadata": {},
   "source": [
    "## Part 2: Data Cleaning and Preprocessing\n",
    "\n",
    "### Task 2.1: Handling Missing Values\n",
    "\n",
    "Implement strategies to handle missing values in the dataset:\n",
    "\n",
    "- For categorical columns: Replace with mode or a placeholder\n",
    "- For numerical columns: Replace with mean, median, or a calculated value\n",
    "- Document your approach and justify your choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfb943f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4a785c",
   "metadata": {},
   "source": [
    "### Task 2.2: Handling Inconsistent Data\n",
    "\n",
    "Fix inconsistencies in the dataset:\n",
    "\n",
    "- Standardize character names (capitalization, extra spaces)\n",
    "- Correct country name spellings\n",
    "- Convert any string values in numerical columns to appropriate numeric types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f5f072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db16a26d",
   "metadata": {},
   "source": [
    "### Task 2.3: Outlier Detection and Handling\n",
    "\n",
    "Detect and handle outliers in numerical columns:\n",
    "\n",
    "- Use visualization methods (box plots) to identify outliers\n",
    "- Use statistical methods (Z-score or IQR) to confirm outliers\n",
    "- Implement an appropriate strategy (capping, removing, or transforming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6c6fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6dcc3a",
   "metadata": {},
   "source": [
    "### Task 2.4: Data Transformation\n",
    "\n",
    "Apply appropriate transformations to prepare the data for analysis:\n",
    "\n",
    "- Standardize or normalize numerical features if needed\n",
    "- Create any useful derived features\n",
    "- Encode categorical variables if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b6811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3153fb",
   "metadata": {},
   "source": [
    "## Part 3: Advanced Analysis (Optional)\n",
    "\n",
    "### Task 3.1: Multicollinearity Analysis using VIF\n",
    "\n",
    "Variance Inflation Factor (VIF) helps identify correlated features in your dataset:\n",
    "\n",
    "> You'll need to install statsmodels first: `pip install statsmodels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e0bc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Create a new dataframe with only numeric columns\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Calculate VIF for each feature\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = numeric_df.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(numeric_df.values, i) for i in range(len(numeric_df.columns))]\n",
    "\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5ebbdd",
   "metadata": {},
   "source": [
    "> **Note**: VIF values > 5 indicate high multicollinearity. [Learn more about VIF here](https://www.geeksforgeeks.org/detecting-multicollinearity-with-vif-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb82232",
   "metadata": {},
   "source": [
    "### Task 3.2: Dimensionality Reduction with PCA (Optional)\n",
    "\n",
    "If you'd like to explore dimensionality reduction:\n",
    "> **Note**: [Learn more about PCA here](https://www.kaggle.com/code/vipulgandhi/pca-beginner-friendly-detailed-explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f3d86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(numeric_df)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA()\n",
    "pca_data = pca.fit_transform(scaled_data)\n",
    "\n",
    "# Create a scree plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_), marker='o')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('Explained Variance by Components')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bdfa04",
   "metadata": {},
   "source": [
    "## Part 4: Conclusion and Documentation\n",
    "\n",
    "### Task 4.1: Summarize Your Findings\n",
    "\n",
    "Write a summary of:\n",
    "- The initial state of the data\n",
    "- All issues identified\n",
    "- Methods used to address each issue\n",
    "- The final state of the cleaned dataset\n",
    "- Any insights gained during the process\n",
    "\n",
    "### Task 4.2: Save Your Cleaned Dataset\n",
    "\n",
    "Save your cleaned and preprocessed dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7970084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code here\n",
    "\n",
    "\n",
    "# END OF TODO\n",
    "df_cleaned.to_csv('cartoon_popularity_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1c2f79",
   "metadata": {},
   "source": [
    "## Submission Guidelines\n",
    "\n",
    "1. Submit your completed Jupyter notebook (.ipynb file)\n",
    "2. Include the original and cleaned datasets\n",
    "3. Make sure all code cells are executed and outputs are visible\n",
    "4. Add appropriate markdown cells explaining your approach and findings\n",
    "5. Ensure your notebook is well-organized and follows a logical flow\n",
    "\n",
    "\n",
    "\n",
    "## Resources\n",
    "\n",
    "### Pandas and Data Manipulation\n",
    "- [Pandas Documentation](https://pandas.pydata.org/docs/)\n",
    "- [10 Minutes to Pandas](https://pandas.pydata.org/docs/user_guide/10min.html)\n",
    "- [Kaggle: Pandas Tutorial](https://www.kaggle.com/learn/pandas)\n",
    "\n",
    "### Data Visualization\n",
    "- [Matplotlib Documentation](https://matplotlib.org/stable/contents.html)\n",
    "- [Matplotlib Gallery](https://matplotlib.org/stable/gallery/index.html)\n",
    "- [Kaggle: Data Visualization](https://www.kaggle.com/learn/data-visualization)\n",
    "\n",
    "### Data Cleaning and Preprocessing\n",
    "- [Handling Missing Values](https://towardsdatascience.com/data-cleaning-with-python-and-pandas-detecting-missing-values-3e9c6ebcf78b)\n",
    "- [Outlier Detection Methods](https://machinelearningmastery.com/how-to-use-statistics-to-identify-outliers-in-data/)\n",
    "- [GeeksforGeeks: Data Preprocessing](https://www.geeksforgeeks.org/data-preprocessing-in-data-mining/)\n",
    "\n",
    "### Advanced Topics\n",
    "- [Understanding VIF](https://www.geeksforgeeks.org/detecting-multicollinearity-with-vif-python/)\n",
    "- [PCA Explained](https://www.kaggle.com/code/vipulgandhi/pca-beginner-friendly-detailed-explanation)\n",
    "\n",
    "---\n",
    "\n",
    "**Good luck with your assignment! Remember, data preprocessing is an art as much as it is a science â€“ there are often multiple valid approaches to handle data issues, so freely use your intution wherever you need.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
